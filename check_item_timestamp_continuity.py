#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç‰©å“æ•°æ®æ—¶é—´è¿ç»­æ€§æ£€æŸ¥è„šæœ¬
æ£€æŸ¥ data_new ç›®å½•ä¸‹ä»¥çº¯æ•°å­— ID å‘½åçš„ json æ–‡ä»¶æ—¶é—´æˆ³æ˜¯å¦ç¬¦åˆè§„èŒƒï¼š
1. æ—¶é—´æˆ³æ˜¯å¦ä¸ºåŒ—äº¬æ—¶é—´æ•´ç‚¹
2. ç›¸é‚»è®°å½•æ—¶é—´æˆ³ç›¸å·® 1 å°æ—¶
"""

import json
import os
import glob
from datetime import datetime, timezone, timedelta
from typing import List, Dict, Any, Tuple

ONE_HOUR_MS = 60 * 60 * 1000


def find_missing_timestamps(data: List[Dict[str, Any]]) -> Tuple[List[int], List[Tuple[int, int]]]:
    """
    æ‰¾å‡ºå¯é€šè¿‡çº¿æ€§æ’å€¼å¡«è¡¥çš„ç¼ºå¤±æ—¶é—´æˆ³ä»¥åŠæ— æ³•è¢«æ•´é™¤çš„é—´éš”ã€‚
    è¿”å›:
        missing_timestamps: éœ€è¦æ’å€¼çš„æ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰
        irregular_gaps: æ— æ³•æ•´é™¤çš„é—´éš”åˆ—è¡¨ï¼Œå…ƒç´ ä¸º (å‰ä¸€ä¸ªæ—¶é—´æˆ³, å½“å‰æ—¶é—´æˆ³)
    """
    missing_timestamps: List[int] = []
    irregular_gaps: List[Tuple[int, int]] = []

    for i in range(1, len(data)):
        prev = data[i - 1]
        curr = data[i]
        if 't' not in prev or 't' not in curr:
            continue

        try:
            prev_ts = int(prev['t'])
            curr_ts = int(curr['t'])
        except (ValueError, TypeError):
            continue

        interval = curr_ts - prev_ts
        if interval <= ONE_HOUR_MS:
            continue

        if interval % ONE_HOUR_MS != 0:
            irregular_gaps.append((prev_ts, curr_ts))
            continue

        missing_count = interval // ONE_HOUR_MS - 1
        for step in range(1, missing_count + 1):
            missing_timestamps.append(prev_ts + ONE_HOUR_MS * step)

    return missing_timestamps, irregular_gaps


def interpolate_value(prev_value: Any, next_value: Any, ratio: float) -> Any:
    """å¯¹æ•°å€¼è¿›è¡Œçº¿æ€§æ’å€¼ï¼Œæ— æ³•è½¬æ¢ä¸ºæµ®ç‚¹æ•°æ—¶è¿”å›å‰ä¸€ä¸ªå€¼ã€‚"""
    try:
        prev_f = float(prev_value)
        next_f = float(next_value)
    except (TypeError, ValueError):
        return prev_value
    return prev_f + (next_f - prev_f) * ratio


def create_interpolated_entry(
    prev_entry: Dict[str, Any],
    next_entry: Dict[str, Any],
    missing_ts: int,
    ratio: float,
) -> Dict[str, Any]:
    """ç”Ÿæˆçº¿æ€§æ’å€¼åçš„æ•°æ®ç‚¹ã€‚"""
    interpolated = {'t': str(missing_ts)}

    for field in ['o', 'h', 'l', 'c', 'v']:
        if field in prev_entry and field in next_entry:
            interpolated[field] = interpolate_value(prev_entry[field], next_entry[field], ratio)
        elif field in prev_entry:
            interpolated[field] = prev_entry[field]
        elif field in next_entry:
            interpolated[field] = next_entry[field]

    extra_keys = set(prev_entry.keys()).union(next_entry.keys()) - {'t', 'o', 'h', 'l', 'c', 'v'}
    for key in extra_keys:
        interpolated[key] = prev_entry.get(key, next_entry.get(key))

    return interpolated


def fill_missing_points(file_path: str) -> int:
    """å¯¹æŒ‡å®šæ–‡ä»¶å†…çš„ç¼ºå¤±æ—¶é—´ç‚¹è¿›è¡Œçº¿æ€§æ’å€¼å¡«è¡¥ï¼Œè¿”å›æ’å€¼æ•°é‡ã€‚"""
    data = load_json_file(file_path)
    if not data:
        print(f"   â€¢ æ— æ³•åŠ è½½æ•°æ®ï¼Œè·³è¿‡å¡«è¡¥: {os.path.basename(file_path)}")
        return 0

    new_data: List[Dict[str, Any]] = []
    inserted = 0

    for i in range(len(data) - 1):
        prev_entry = data[i]
        next_entry = data[i + 1]
        new_data.append(prev_entry)

        if 't' not in prev_entry or 't' not in next_entry:
            continue

        try:
            prev_ts = int(prev_entry['t'])
            next_ts = int(next_entry['t'])
        except (ValueError, TypeError):
            continue

        interval = next_ts - prev_ts
        if interval <= ONE_HOUR_MS or interval % ONE_HOUR_MS != 0:
            continue

        missing_count = interval // ONE_HOUR_MS - 1
        for step in range(1, missing_count + 1):
            ratio = step / (missing_count + 1)
            missing_ts = prev_ts + ONE_HOUR_MS * step
            interpolated_entry = create_interpolated_entry(prev_entry, next_entry, missing_ts, ratio)
            new_data.append(interpolated_entry)
            inserted += 1

    if data:
        new_data.append(data[-1])

    if inserted:
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(new_data, f, ensure_ascii=False, indent=2)
        print(f"   â€¢ å·²å¡«è¡¥ {inserted} ä¸ªç¼ºå¤±ç‚¹: {os.path.basename(file_path)}")
    else:
        print(f"   â€¢ æœªå‘ç°å¯å¡«è¡¥çš„ç¼ºå¤±ç‚¹: {os.path.basename(file_path)}")

    return inserted


def load_json_file(file_path: str) -> List[Dict[str, Any]]:
    """åŠ è½½JSONæ–‡ä»¶"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
            if isinstance(data, list):
                return data
            else:
                print(f"âŒ æ–‡ä»¶æ ¼å¼ä¸æ˜¯æ•°ç»„: {file_path}")
                return []
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶ {file_path} å¤±è´¥: {e}")
        return []


def timestamp_to_beijing_time(ts_str: str) -> datetime:
    """å°†æ¯«ç§’æ—¶é—´æˆ³è½¬æ¢ä¸ºåŒ—äº¬æ—¶é—´"""
    ts = int(ts_str)
    # å…ˆè½¬ä¸ºUTCæ—¶é—´
    utc_time = datetime.fromtimestamp(ts / 1000, tz=timezone.utc)
    # è½¬ä¸ºåŒ—äº¬æ—¶é—´ (UTC+8)
    beijing_time = utc_time + timedelta(hours=8)
    return beijing_time


def is_valid_time_point(beijing_time: datetime) -> bool:
    """æ£€æŸ¥æ—¶é—´æ˜¯å¦ä¸ºåŒ—äº¬æ—¶é—´æ•´ç‚¹"""
    return beijing_time.minute == 0 and beijing_time.second == 0


def check_timestamp_continuity(file_path: str) -> Tuple[bool, List[str], List[int]]:
    """æ£€æŸ¥æ—¶é—´æˆ³è¿ç»­æ€§"""
    print(f"ğŸ” æ£€æŸ¥æ—¶é—´æˆ³è¿ç»­æ€§: {os.path.basename(file_path)}")

    # åŠ è½½æ•°æ®
    data = load_json_file(file_path)
    if not data:
        return False, ["æ— æ³•è¯»å–æ–‡ä»¶æˆ–æ–‡ä»¶ä¸ºç©º"], []

    if len(data) < 2:
        return True, ["æ•°æ®é‡ä¸è¶³2æ¡ï¼Œæ— æ³•æ£€æŸ¥è¿ç»­æ€§"], []

    issues = []
    intervals = []
    valid_time_points = []
    invalid_time_points = []

    # æ£€æŸ¥æ¯ä¸ªæ—¶é—´æˆ³
    for i, item in enumerate(data):
        if 't' not in item:
            issues.append(f"ç¬¬ {i+1} æ¡è®°å½•ç¼ºå°‘æ—¶é—´æˆ³å­—æ®µ")
            continue

        ts_str = item['t']
        try:
            ts = int(ts_str)
            beijing_time = timestamp_to_beijing_time(ts_str)

            # æ£€æŸ¥æ˜¯å¦ä¸ºæœ‰æ•ˆæ—¶é—´ç‚¹
            if is_valid_time_point(beijing_time):
                valid_time_points.append((i+1, beijing_time))
            else:
                invalid_time_points.append((i+1, beijing_time))
                issues.append(f"ç¬¬ {i+1} æ¡è®°å½•ä¸æ˜¯æ ‡å‡†æ—¶é—´ç‚¹: {beijing_time.strftime('%Y-%m-%d %H:%M:%S')}")

            # æ£€æŸ¥é—´éš”ï¼ˆä»ç¬¬äºŒæ¡è®°å½•å¼€å§‹ï¼‰
            if i > 0:
                prev_ts = int(data[i-1]['t'])
                interval = ts - prev_ts
                intervals.append(interval)

                if interval != ONE_HOUR_MS:  # 1å°æ—¶ = 3600000æ¯«ç§’
                    prev_time = timestamp_to_beijing_time(data[i-1]['t'])
                    curr_time = beijing_time
                    issues.append(f"ç¬¬ {i} æ¡è®°å½•é—´éš”å¼‚å¸¸: {interval} æ¯«ç§’ (åº”ä¸º{ONE_HOUR_MS}æ¯«ç§’)")
                    issues.append(f"  ä» {prev_time.strftime('%Y-%m-%d %H:%M:%S')} åˆ° {curr_time.strftime('%Y-%m-%d %H:%M:%S')}")

        except (ValueError, TypeError) as e:
            issues.append(f"ç¬¬ {i+1} æ¡è®°å½•æ—¶é—´æˆ³æ ¼å¼é”™è¯¯: {ts_str}")

    missing_timestamps, irregular_gaps = find_missing_timestamps(data)
    for prev_ts, curr_ts in irregular_gaps:
        prev_time = timestamp_to_beijing_time(str(prev_ts))
        curr_time = timestamp_to_beijing_time(str(curr_ts))
        issues.append(
            f"å­˜åœ¨æ— æ³•æ•´é™¤1å°æ—¶çš„æ—¶é—´é—´éš”: ä» {prev_time.strftime('%Y-%m-%d %H:%M:%S')} "
            f"åˆ° {curr_time.strftime('%Y-%m-%d %H:%M:%S')}"
        )

    # ç»Ÿè®¡ä¿¡æ¯
    print(f"ğŸ“Š æ—¶é—´ç‚¹ç»Ÿè®¡:")
    print(f"   â€¢ æœ‰æ•ˆæ—¶é—´ç‚¹: {len(valid_time_points)} ä¸ª")
    print(f"   â€¢ æ— æ•ˆæ—¶é—´ç‚¹: {len(invalid_time_points)} ä¸ª")

    if invalid_time_points:
        print(f"âŒ æ— æ•ˆæ—¶é—´ç‚¹ç¤ºä¾‹:")
        for idx, time_point in invalid_time_points[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
            print(f"   â€¢ ç¬¬{idx}æ¡: {time_point.strftime('%Y-%m-%d %H:%M:%S')}")
        if len(invalid_time_points) > 3:
            print(f"   â€¢ ... è¿˜æœ‰ {len(invalid_time_points) - 3} ä¸ªæ— æ•ˆæ—¶é—´ç‚¹")

    if intervals:
        unique_intervals = set(intervals)
        if len(unique_intervals) == 1 and ONE_HOUR_MS in unique_intervals:
            print(f"âœ… æ—¶é—´æˆ³é—´éš”æ£€æŸ¥é€šè¿‡: {len(data)} æ¡è®°å½•ï¼Œé—´éš”å‡ä¸º1å°æ—¶")
        else:
            interval_counts = {value: intervals.count(value) for value in unique_intervals}
            print(f"âš ï¸  å‘ç°é—´éš”é—®é¢˜ï¼Œé—´éš”åˆ†å¸ƒ: {interval_counts}")

    if missing_timestamps:
        print(f"â³ å‘ç° {len(missing_timestamps)} ä¸ªå¯é€šè¿‡çº¿æ€§æ’å€¼å¡«è¡¥çš„ç¼ºå¤±æ—¶é—´ç‚¹")
        preview = missing_timestamps[:3]
        for ts in preview:
            bt = timestamp_to_beijing_time(str(ts))
            print(f"   â€¢ ç¼ºå¤±æ—¶é—´ç‚¹: {bt.strftime('%Y-%m-%d %H:%M:%S')}")
        if len(missing_timestamps) > len(preview):
            print(f"   â€¢ ... è¿˜æœ‰ {len(missing_timestamps) - len(preview)} ä¸ªç¼ºå¤±ç‚¹")

    return len(issues) == 0, issues, missing_timestamps


def get_item_files() -> List[str]:
    """è·å–æ‰€æœ‰ç‰©å“æ–‡ä»¶ï¼ˆä»…åŒ¹é…çº¯æ•°å­— ID å‘½åçš„ JSONï¼‰"""
    pattern = os.path.join('data_new', '*.json')
    all_files = glob.glob(pattern)

    item_files = []
    for file in all_files:
        basename = os.path.basename(file)
        name, ext = os.path.splitext(basename)

        if ext != '.json':
            continue

        if not name.isdigit():
            continue

        item_files.append(file)

    return sorted(item_files)


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æ£€æŸ¥ç‰©å“æ•°æ®æ—¶é—´è¿ç»­æ€§...")

    # è·å–æ‰€æœ‰ç‰©å“æ–‡ä»¶
    item_files = get_item_files()

    if not item_files:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•ç‰©å“æ–‡ä»¶")
        return

    print(f"ğŸ“ æ‰¾åˆ° {len(item_files)} ä¸ªç‰©å“æ–‡ä»¶")

    # æ£€æŸ¥æ‰€æœ‰æ–‡ä»¶
    passed_files = []
    failed_files = []

    missing_summary: Dict[str, List[int]] = {}

    for file_path in item_files:
        print(f"\n{'='*60}")
        is_valid, issues, missing_timestamps = check_timestamp_continuity(file_path)

        if is_valid:
            print(f"âœ… {os.path.basename(file_path)}: æ—¶é—´æˆ³æ£€æŸ¥é€šè¿‡")
            passed_files.append(file_path)
        else:
            print(f"âŒ {os.path.basename(file_path)}: å‘ç° {len(issues)} ä¸ªé—®é¢˜:")
            for issue in issues[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ªé—®é¢˜
                print(f"   â€¢ {issue}")
            if len(issues) > 10:
                print(f"   â€¢ ... è¿˜æœ‰ {len(issues) - 10} ä¸ªé—®é¢˜")
            failed_files.append(file_path)

        if missing_timestamps:
            missing_summary[file_path] = missing_timestamps

    if missing_summary:
        print("\nâ± å¯é€šè¿‡çº¿æ€§æ’å€¼å¡«è¡¥çš„ç¼ºå¤±æ—¶é—´ç‚¹æ±‡æ€»:")
        total_missing = 0
        for file_path, timestamps in missing_summary.items():
            total_missing += len(timestamps)
            sample_times = [
                timestamp_to_beijing_time(str(ts)).strftime('%Y-%m-%d %H:%M:%S')
                for ts in timestamps[:3]
            ]
            preview = 'ï¼Œ'.join(sample_times)
            if len(timestamps) > 3:
                preview += f"ï¼Œ... ç­‰ {len(timestamps)} ä¸ªæ—¶é—´ç‚¹"
            print(f"   â€¢ {os.path.basename(file_path)} ç¼ºå¤± {len(timestamps)} ä¸ªæ—¶é—´ç‚¹ -> {preview}")
        print(f"   â€¢ æ€»è®¡ç¼ºå¤±æ—¶é—´ç‚¹: {total_missing} ä¸ª")

    # æœ€ç»ˆç»Ÿè®¡
    print(f"\n{'='*60}")
    print(f"ğŸ“Š æ£€æŸ¥å®Œæˆç»Ÿè®¡:")
    print(f"   â€¢ æ€»æ–‡ä»¶æ•°: {len(item_files)}")
    print(f"   â€¢ é€šè¿‡æ£€æŸ¥: {len(passed_files)} ä¸ª")
    print(f"   â€¢ æœªé€šè¿‡æ£€æŸ¥: {len(failed_files)} ä¸ª")

    if failed_files:
        print(f"\nâŒ æœªé€šè¿‡æ£€æŸ¥çš„æ–‡ä»¶:")
        for file_path in failed_files:
            print(f"   â€¢ {os.path.basename(file_path)}")

    print(f"\n{'='*60}")
    if len(failed_files) == 0:
        print("ğŸ‰ æ‰€æœ‰æ–‡ä»¶çš„æ—¶é—´æˆ³æ£€æŸ¥éƒ½é€šè¿‡äº†ï¼")
    else:
        print(f"âš ï¸  æœ‰ {len(failed_files)} ä¸ªæ–‡ä»¶å­˜åœ¨é—®é¢˜ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°è¾“å‡º")
    print(f"{'='*60}")

    if missing_summary:
        confirm = input("\næ˜¯å¦ä½¿ç”¨çº¿æ€§æ’å€¼å¡«è¡¥è¿™äº›ç¼ºå¤±æ•°æ®ç‚¹ï¼Ÿ(y/N): ").strip().lower()
        if confirm in {'y', 'yes', 'æ˜¯', 'å¥½', 'ok'}:
            print("\nğŸ”§ å¼€å§‹å¡«è¡¥ç¼ºå¤±æ—¶é—´ç‚¹...")
            total_inserted = 0
            for file_path in missing_summary:
                inserted = fill_missing_points(file_path)
                total_inserted += inserted
            print(f"\nâœ… å¡«è¡¥å®Œæˆï¼Œæ€»å…±æ–°å¢ {total_inserted} ä¸ªæ•°æ®ç‚¹")
        else:
            print("\nâ„¹ï¸ å·²å–æ¶ˆå¡«è¡¥æ“ä½œï¼ŒåŸå§‹æ•°æ®æœªåšæ”¹åŠ¨")


if __name__ == "__main__":
    main()
